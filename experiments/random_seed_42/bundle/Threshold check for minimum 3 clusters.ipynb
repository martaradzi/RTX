{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import plot, show, savefig, xlim, figure,  ylim, legend, boxplot, setp, axes\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data.csv')\n",
    "columns = list(df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette_scores(model, test_data, n_clusters_min, n_clusters_max, title):\n",
    "    \"\"\" Plot silhouette scores and return the best number of clusters\"\"\"\n",
    "\n",
    "    if len(model.subcluster_labels_) >= 2:\n",
    "\n",
    "        silhouette_scores = []\n",
    "\n",
    "        clusters_range = range(n_clusters_min, n_clusters_max+1)\n",
    "        results_dict = []\n",
    "        # print(clusters_range)\n",
    "        for number in clusters_range:\n",
    "            # make a copy of the model so as not to mess up the 'correct' model\n",
    "            model_cpy = copy.deepcopy(model)\n",
    "            model_cpy.set_params(n_clusters=number)\n",
    "\n",
    "            model_cpy.partial_fit()\n",
    "            labels = model_cpy.predict(test_data)\n",
    "            # print(labels)\n",
    "            try: \n",
    "                s = metrics.silhouette_score(test_data, labels, metric='euclidean')\n",
    "                silhouette_scores.append(s)\n",
    "                results_dict.append((number, s))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        silhouette_range = [i[0] for i in results_dict]  \n",
    "#         plt.plot(silhouette_range[:], silhouette_scores[:], label = title)\n",
    "#         plt.xlabel('Number of Clusters')\n",
    "#         plt.ylabel('Silhouette Score')\n",
    "#         plt.title(title)\n",
    "#         plt.legend(bbox_to_anchor=(0, 1), loc='upper left', ncol=1)\n",
    "#         plt.savefig(folder + 'silhouette_'+ save_graph_name +'.png')\n",
    "#         plt.show()\n",
    "#         plt.close() \n",
    "        max_score = max(silhouette_scores)\n",
    "#         print(results_dict)\n",
    "        for i in results_dict:\n",
    "            if i[1] == max_score:\n",
    "                print(\"The highest silhouette scores(\" + str(max_score) + \") is for \" + str(i[0]) + \" clusers\")\n",
    "#                 print(f'{max_score}')\n",
    "                return int(i[0])\n",
    "    else:\n",
    "        print('couldnt get the scores, plz help')\n",
    "        print('returning number of clusters = ' + str(n_clusters_min))\n",
    "#         model_cpy = copy.deepcopy(model)\n",
    "#         model_cpy.set_params(n_clusters=2)\n",
    "\n",
    "#         model_cpy.partial_fit()\n",
    "#         labels = model_cpy.predict(test_data)\n",
    "#         s = metrics.silhouette_score(test_data, labels, metric='euclidean')\n",
    "#         print(s)\n",
    "#         print('\\n')\n",
    "        return n_clusters_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_removal(df):\n",
    "    data_split_modified_z = df[['median_overhead', 'q1_overhead', 'q3_overhead', 'p9_overhead', 'totalCarNumber', 'index']].copy()\n",
    "    data_split_modified_z = data_split_modified_z.to_numpy()\n",
    "    data_split_modified_z_12 = np.split(data_split_modified_z, 1)\n",
    "    indexes = [] \n",
    "\n",
    "    for d in range(len(data_split_modified_z_12)):\n",
    "        ind = []\n",
    "        k = len(data_split_modified_z_12[d])\n",
    "        for i in [0, 1, 2, 3]:\n",
    "            ys = data_split_modified_z_12[d][:,i] \n",
    "            median_y = np.median(ys)\n",
    "            median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])\n",
    "    #         print(median_absolute_deviation_y)\n",
    "            for y in range(len(data_split_modified_z_12[d])):\n",
    "                modified_z_score = 0.6745 * (data_split_modified_z_12[d][y, i] - median_y) / median_absolute_deviation_y\n",
    "    #             z_score = (data_split[d][y, i]  - mean_ys) / std_ys\n",
    "                if np.abs(modified_z_score) > 3.5:\n",
    "                    ind.append(y)\n",
    "\n",
    "\n",
    "        data_split_modified_z_12[d] = np.delete(data_split_modified_z_12[d], ind, axis=0)\n",
    "#         print('Outliers detected: ' + str((k - len(data_split_modified_z_12[d]))))\n",
    "\n",
    "    data_split_modified_z_12 = np.concatenate(data_split_modified_z_12, axis=0)\n",
    "    return data_split_modified_z_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the whole two days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "\n",
      "\n",
      "[144, 162, 180, 198, 216, 234, 252, 270]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.iloc[144:, :]\n",
    "indexes = np.array_split(df.index,8, axis=0)\n",
    "for i,index in enumerate(indexes):\n",
    "    df.loc[index,'group'] = i\n",
    "    \n",
    "df['c'] = df['group'].diff()\n",
    "df_filtered = df[df['c'] != 0]\n",
    "\n",
    "index_list = df_filtered.index.tolist() # list of the start poisitions of index for change of values \n",
    "print(len(index_list))\n",
    "print('\\n')\n",
    "print(index_list)\n",
    "\n",
    "l_mod = index_list + [max(index_list)+1] # creating a list of indexes to iterate over (must have 0 in it)\n",
    "list_of_dfs = [df.iloc[l_mod[n]:l_mod[n+1]] for n in range(len(l_mod)-1)] # creating a list of dfs for each index\n",
    "\n",
    "len(list_of_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marta/env/lib/python3.6/site-packages/numpy-1.18.2-py3.6-linux-x86_64.egg/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/marta/env/lib/python3.6/site-packages/numpy-1.18.2-py3.6-linux-x86_64.egg/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-702c5398d071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnumpy_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutliers_removal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mremoved_outliers_numpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel_001_whole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnew_nmpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremoved_outliers_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/scikit_learn-0.22.2.post1-py3.6-linux-x86_64.egg/sklearn/cluster/_birch.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/scikit_learn-0.22.2.post1-py3.6-linux-x86_64.egg/sklearn/cluster/_birch.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mbranching_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranching_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/scikit_learn-0.22.2.post1-py3.6-linux-x86_64.egg/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    584\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 586\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "###############     THRESHOLD 0.01       #################\n",
    "##########################################################\n",
    "\n",
    "\n",
    "model_001_whole = Birch(n_clusters=None, threshold=0.01)\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "removed_outliers_numpy = []\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "# add_data_to_this = pd.DataFrame(columns = columns)\n",
    "for i in list_of_dfs:\n",
    "    numpy_array = outliers_removal(i)\n",
    "    removed_outliers_numpy.append(numpy_array)\n",
    "    model_001_whole.partial_fit(numpy_array[:, :-2])\n",
    "    \n",
    "new_nmpy = np.concatenate(removed_outliers_numpy, axis=0)\n",
    "print('THRESHOLD 0.01')\n",
    "n = plot_silhouette_scores(model_001_whole, new_nmpy[:, :-2], 3, 10, 'threshold 0.2')\n",
    "model_001_whole.set_params(n_clusters = n)\n",
    "model_001_whole.partial_fit()\n",
    "print('\\n')\n",
    "\n",
    "lablels_001 = model_001_whole.predict(new_nmpy[:, :-2])\n",
    "\n",
    "##########################################################\n",
    "###############     THRESHOLD 0.05      #################\n",
    "##########################################################\n",
    "\n",
    "\n",
    "model_005_whole = Birch(n_clusters=None, threshold=0.05)\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "removed_outliers_numpy = []\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "# add_data_to_this = pd.DataFrame(columns = columns)\n",
    "for i in list_of_dfs:\n",
    "    numpy_array = outliers_removal(i)\n",
    "    removed_outliers_numpy.append(numpy_array)\n",
    "    model_005_whole.partial_fit(numpy_array[:, :-2])\n",
    "    \n",
    "new_nmpy = np.concatenate(removed_outliers_numpy, axis=0)\n",
    "print('THRESHOLD 0.05')\n",
    "n = plot_silhouette_scores(model_005_whole, new_nmpy[:, :-2], 3, 10, 'threshold 0.2')\n",
    "model_005_whole.set_params(n_clusters = n)\n",
    "model_005_whole.partial_fit()\n",
    "print('\\n')\n",
    "lablels_005 = model_005_whole.predict(new_nmpy[:, :-2])\n",
    "\n",
    "##########################################################\n",
    "###############     THRESHOLD 0.1       #################\n",
    "##########################################################\n",
    "\n",
    "\n",
    "model_01_whole = Birch(n_clusters=None, threshold=0.1)\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "removed_outliers_numpy = []\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "# add_data_to_this = pd.DataFrame(columns = columns)\n",
    "for i in list_of_dfs:\n",
    "    numpy_array = outliers_removal(i)\n",
    "    removed_outliers_numpy.append(numpy_array)\n",
    "    model_01_whole.partial_fit(numpy_array[:, :-2])\n",
    "    \n",
    "new_nmpy = np.concatenate(removed_outliers_numpy, axis=0)\n",
    "print('THRESHOLD 0.1')\n",
    "n = plot_silhouette_scores(model_01_whole, new_nmpy[:, :-2], 3, 10, 'threshold 0.2')\n",
    "model_01_whole.set_params(n_clusters = n)\n",
    "model_01_whole.partial_fit()\n",
    "print('\\n')\n",
    "\n",
    "lablels_01 = model_01_whole.predict(new_nmpy[:, :-2])\n",
    "\n",
    "\n",
    "##########################################################\n",
    "###############     THRESHOLD 0.2       #################\n",
    "##########################################################\n",
    "\n",
    "\n",
    "model_02_whole = Birch(n_clusters=None, threshold=0.2)\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "removed_outliers_numpy = []\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "# add_data_to_this = pd.DataFrame(columns = columns)\n",
    "for i in list_of_dfs:\n",
    "    numpy_array = outliers_removal(i)\n",
    "    removed_outliers_numpy.append(numpy_array)\n",
    "    model_02_whole.partial_fit(numpy_array[:, :-2])\n",
    "    \n",
    "new_nmpy = np.concatenate(removed_outliers_numpy, axis=0)\n",
    "print('THRESHOLD 0.2')\n",
    "n = plot_silhouette_scores(model_02_whole, new_nmpy[:, :-2], 3, 10, 'threshold 0.2')\n",
    "model_02_whole.set_params(n_clusters = n)\n",
    "model_02_whole.partial_fit()\n",
    "print('\\n')\n",
    "\n",
    "lablels_02 = model_02_whole.predict(new_nmpy[:, :-2])\n",
    "\n",
    "\n",
    "##########################################################\n",
    "###############     THRESHOLD 0.3      #################\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "model_03_whole = Birch(n_clusters=None, threshold=0.3)\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "removed_outliers_numpy = []\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "# add_data_to_this = pd.DataFrame(columns = columns)\n",
    "for i in list_of_dfs:\n",
    "    numpy_array = outliers_removal(i)\n",
    "    removed_outliers_numpy.append(numpy_array)\n",
    "    model_03_whole.partial_fit(numpy_array[:, :-2])\n",
    "    \n",
    "new_nmpy = np.concatenate(removed_outliers_numpy, axis=0)\n",
    "print('THRESHOLD 0.3')\n",
    "n = plot_silhouette_scores(model_03_whole, new_nmpy[:, :-2], 3, 10, 'threshold 0.3')\n",
    "model_03_whole.set_params(n_clusters = n)\n",
    "model_03_whole.partial_fit()\n",
    "print('\\n')\n",
    "\n",
    "lablels_03 = model_03_whole.predict(new_nmpy[:, :-2])\n",
    "\n",
    "##########################################################\n",
    "###############     THRESHOLD 0.5      #################\n",
    "##########################################################\n",
    "\n",
    "model_05_whole = Birch(n_clusters=None, threshold=0.5)\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "removed_outliers_numpy = []\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "# add_data_to_this = pd.DataFrame(columns = columns)\n",
    "for i in list_of_dfs:\n",
    "    numpy_array = outliers_removal(i)\n",
    "    removed_outliers_numpy.append(numpy_array)\n",
    "    model_05_whole.partial_fit(numpy_array[:, :-2])\n",
    "    \n",
    "print('THRESHOLD 0.5')\n",
    "new_nmpy = np.concatenate(removed_outliers_numpy, axis=0)\n",
    "n = plot_silhouette_scores(model_05_whole, new_nmpy[:, :-2], 3 , 10, 'threshold 0.5')\n",
    "model_05_whole.set_params(n_clusters = n)\n",
    "model_05_whole.partial_fit()\n",
    "print('\\n')\n",
    "\n",
    "lablels_05 = model_05_whole.predict(new_nmpy[:, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axs = plt.subplots(nrows=6, ncols=1,figsize=(17,25))\n",
    "\n",
    "axs[0].scatter(new_nmpy[:,5], new_nmpy[:,4], c=lablels_001, cmap='rainbow', alpha=0.7)\n",
    "axs[0].axvline(x=143, color='g')\n",
    "axs[0].set_ylabel('Number of cars')\n",
    "axs[0].set_xlabel('Time of the day')\n",
    "axs[0].title.set_text(\"Threshold 0.01\")\n",
    "\n",
    "axs[1].scatter(new_nmpy[:,5], new_nmpy[:,4], c=lablels_005, cmap='rainbow', alpha=0.7)\n",
    "axs[1].axvline(x=143, color='g')\n",
    "axs[1].set_ylabel('Number of cars')\n",
    "axs[1].set_xlabel('Time of the day')\n",
    "axs[1].title.set_text(\"Threshold 0.05\")\n",
    "\n",
    "axs[2].scatter(new_nmpy[:,5], new_nmpy[:,4], c=lablels_01, cmap='rainbow', alpha=0.7) \n",
    "axs[2].axvline(x=143, color='g')\n",
    "axs[2].set_ylabel('Number of cars')\n",
    "axs[2].set_xlabel('Time of the day')\n",
    "axs[2].title.set_text(\"Threshold 0.1\")\n",
    "\n",
    "axs[3].scatter(new_nmpy[:,5], new_nmpy[:,4], c=lablels_02, cmap='rainbow', alpha=0.7)  \n",
    "axs[3].axvline(x=143, color='g')\n",
    "axs[3].set_ylabel('Number of cars')\n",
    "axs[3].set_xlabel('Time of the day')\n",
    "axs[3].title.set_text(\"Threshold 0.2\")\n",
    "\n",
    "axs[4].scatter(new_nmpy[:,5], new_nmpy[:,4], c=lablels_03, cmap='rainbow', alpha=0.7)\n",
    "axs[4].axvline(x=143, color='g')\n",
    "axs[4].set_ylabel('Number of cars')\n",
    "axs[4].set_xlabel('Time of the day')\n",
    "axs[4].title.set_text(\"Threshold 0.3\")\n",
    "\n",
    "axs[5].scatter(new_nmpy[:,5], new_nmpy[:,4], c=lablels_05, cmap='rainbow', alpha=0.7)\n",
    "axs[5].axvline(x=143, color='g')\n",
    "axs[5].set_ylabel('Number of cars')\n",
    "axs[5].set_xlabel('Time of the day')\n",
    "axs[5].title.set_text(\"Threshold 0.5\")\n",
    "\n",
    "figure.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pick threshold with best score and depict a run of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_03_before= Birch(n_clusters=None, threshold=0.1)\n",
    "\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "removed_outliers_numpy = []\n",
    "list_of_nmpys_for_graphs = []\n",
    "\n",
    "labels_dict = {}\n",
    "add_data_to_this = pd.DataFrame(columns = columns)\n",
    "\n",
    "fit_number = 1\n",
    "\n",
    "for i in range(0, len(list_of_dfs)):\n",
    "#     add_data_to_this = pd.concat([add_data_to_this, i])\n",
    "    \n",
    "    numpy_array = outliers_removal(list_of_dfs[i])\n",
    "    \n",
    "    model_03_before.partial_fit(numpy_array[:, :-2])\n",
    "    \n",
    "    model_copy = copy.deepcopy(model_03_before)\n",
    "    \n",
    "    removed_outliers_numpy.append(numpy_array)\n",
    "    new_nmpy = np.concatenate(removed_outliers_numpy, axis=0)\n",
    "    \n",
    "    n = plot_silhouette_scores(model_copy, new_nmpy[:, :-2], 3, 10, 'threshold 0.05')\n",
    "    \n",
    "    model_copy.set_params(n_clusters = n)\n",
    "    model_copy.partial_fit()\n",
    "    \n",
    "    labels_dict[f'fit_{fit_number}'] = model_copy.predict(new_nmpy[:, :-2])\n",
    "    \n",
    "    list_of_nmpys_for_graphs.append(new_nmpy)\n",
    "    fit_number += 1\n",
    "\n",
    "    \n",
    "    \n",
    "col_counter = 0\n",
    "row_counter = 0\n",
    "\n",
    "fit_number = 1\n",
    "\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "\n",
    "figure, axs = plt.subplots(nrows=nrows, ncols=ncols,figsize=(20,15))\n",
    "\n",
    "for i in list_of_nmpys_for_graphs:\n",
    "    \n",
    "#     numpy_array = i.to_numpy()\n",
    "    \n",
    "    figure.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    axs[row_counter,col_counter].scatter(i[:, 5], i[:, 4], c =labels_dict[f'fit_{fit_number}'], cmap='rainbow', alpha=0.7 )\n",
    "    axs[row_counter,col_counter].set_xlabel('Time of the day')\n",
    "    axs[row_counter,col_counter].set_ylim(0, 750)\n",
    "    axs[row_counter,col_counter].set_ylabel('Car number')\n",
    "    axs[row_counter,col_counter].set_title(f'Fit {fit_number}')\n",
    "    \n",
    "    if fit_number >= 9:\n",
    "        axs[row_counter,col_counter].axvline(x=143, color='g')\n",
    "    if col_counter == (ncols-1):\n",
    "        col_counter = 0\n",
    "        row_counter += 1\n",
    "    else:\n",
    "        col_counter += 1\n",
    "    \n",
    "    fit_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
