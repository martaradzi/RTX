{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import plot, show, savefig, xlim, figure,  ylim, legend, boxplot, setp, axes\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>totalCarNumber</th>\n",
       "      <th>numberOfTrips</th>\n",
       "      <th>median_overhead</th>\n",
       "      <th>q1_overhead</th>\n",
       "      <th>q3_overhead</th>\n",
       "      <th>p9_overhead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>826</td>\n",
       "      <td>1.726602</td>\n",
       "      <td>1.389729</td>\n",
       "      <td>2.166549</td>\n",
       "      <td>2.672105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>450</td>\n",
       "      <td>1232</td>\n",
       "      <td>1.724694</td>\n",
       "      <td>1.348019</td>\n",
       "      <td>2.123400</td>\n",
       "      <td>2.727250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>450</td>\n",
       "      <td>1190</td>\n",
       "      <td>1.678615</td>\n",
       "      <td>1.345687</td>\n",
       "      <td>2.079738</td>\n",
       "      <td>2.556367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>450</td>\n",
       "      <td>1135</td>\n",
       "      <td>1.759428</td>\n",
       "      <td>1.365024</td>\n",
       "      <td>2.209888</td>\n",
       "      <td>2.686877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>1198</td>\n",
       "      <td>1.708252</td>\n",
       "      <td>1.355881</td>\n",
       "      <td>2.098686</td>\n",
       "      <td>2.678458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  totalCarNumber  numberOfTrips  median_overhead  q1_overhead  \\\n",
       "0      0             450            826         1.726602     1.389729   \n",
       "1      1             450           1232         1.724694     1.348019   \n",
       "2      2             450           1190         1.678615     1.345687   \n",
       "3      3             450           1135         1.759428     1.365024   \n",
       "4      4             450           1198         1.708252     1.355881   \n",
       "\n",
       "   q3_overhead  p9_overhead  \n",
       "0     2.166549     2.672105  \n",
       "1     2.123400     2.727250  \n",
       "2     2.079738     2.556367  \n",
       "3     2.209888     2.686877  \n",
       "4     2.098686     2.678458  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array split does not result in an equal division",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/numpy-1.18.2-py3.6-linux-x86_64.egg/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_or_sections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f1e3b71df863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# \"\"\" SIZE 12 \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata_split_modified_z_12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_split_modified_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msplit\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/numpy-1.18.2-py3.6-linux-x86_64.egg/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             raise ValueError(\n\u001b[0;32m--> 871\u001b[0;31m                 'array split does not result in an equal division')\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array split does not result in an equal division"
     ]
    }
   ],
   "source": [
    "data_split_modified_z = df[['median_overhead', 'q1_overhead', 'q3_overhead', 'p9_overhead', 'totalCarNumber', 'index']].copy()\n",
    "# data_split_modified_z = data_split_modified_z.iloc[:144, :]\n",
    "data_split_modified_z = data_split_modified_z.to_numpy()\n",
    "# data_split_modified_z_12 = data_split_modified_z.to_numpy()\n",
    "\n",
    "\n",
    "# \"\"\" SIZE 12 \"\"\"\n",
    "data_split_modified_z_12 = np.split(data_split_modified_z, 16)\n",
    "indexes = [] \n",
    "\n",
    "for d in range(len(data_split_modified_z_12)):\n",
    "    ind = []\n",
    "    k = len(data_split_modified_z_12[d])\n",
    "    for i in [0, 1, 2, 3]:\n",
    "        ys = data_split_modified_z_12[d][:,i] \n",
    "        median_y = np.median(ys)\n",
    "        median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])\n",
    "#         print(median_absolute_deviation_y)\n",
    "        for y in range(len(data_split_modified_z_12[d])):\n",
    "            modified_z_score = 0.6745 * (data_split_modified_z_12[d][y, i] - median_y) / median_absolute_deviation_y\n",
    "#             z_score = (data_split[d][y, i]  - mean_ys) / std_ys\n",
    "            if np.abs(modified_z_score) > 3.5:\n",
    "                ind.append(y)\n",
    "\n",
    "\n",
    "    data_split_modified_z_12[d] = np.delete(data_split_modified_z_12[d], ind, axis=0)\n",
    "#     print('Outliers detected: ' + str((k - len(data_split_modified_z_12[d]))))\n",
    "\n",
    "# data_split_modified_z_12 = np.concatenate(data_split_modified_z_12, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_dfs = np.split(data_split_modified_z_12, 10) # split data to make the stream\n",
    "k_np = data_split_modified_z_12[0] # this numpy array is used for the initial k-means\n",
    "list_of_dfs_rest = data_split_modified_z_12[1:8] # this data will be clustered using sequential k-means\n",
    "\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    return np.sqrt(np.sum(point1 - point2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iteration(data, labels, centrois, iteration):\n",
    "    \n",
    "    axes_labels = ['median_overhead', 'q1_overhead', 'q3_overhead', 'p9_overhead',]\n",
    "    axes_feats = [[(0,1),(0,3),(0,2)],\n",
    "                  [(1,3),(1,2),(2,3)],\n",
    "                 ]\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    figure, axs = plt.subplots(nrows=nrows, ncols=ncols,figsize=(13,7))\n",
    "    figure.suptitle(f'iteration {iteration}', fontsize= 16)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            feat = axes_feats[row][col]\n",
    "            figure.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            axs[row, col].scatter(data[:, feat[0]], data[:, feat[1]],  c=labels, cmap='rainbow', alpha=0.7)\n",
    "            axs[row, col].set_ylabel(axes_labels[feat[1]])\n",
    "            axs[row, col].set_xlabel(axes_labels[feat[0]])\n",
    "            for i in range(len(centroids)):\n",
    "                axs[row, col].scatter(centroids[i, feat[0]], centroids[i, feat[1]], c='black', marker='x')\n",
    "                \n",
    "    plt.show(figure)\n",
    "    plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_instance(means, counts, k, instance):\n",
    "    # based on pseudo code from https://www.cs.princeton.edu/courses/archive/fall08/cos436/Duda/C/sk_means.htm\n",
    "    \n",
    "    # distancec of one point to the two clusters\n",
    "    distance_instance_to_clusters = np.zeros(k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        # calculate the distance to each of the cluster means \n",
    "        distance_instance_to_clusters[i] = euclidean_distance(means[i], instance)\n",
    "    \n",
    "    closest_cluster = np.argmin(distance_instance_to_clusters)\n",
    "    \n",
    "    counts[closest_cluster] += 1\n",
    "    \n",
    "    means[closest_cluster] = means[closest_cluster] + (1 / counts[closest_cluster]) * (instance - means[closest_cluster])\n",
    "    \n",
    "    return closest_cluster, means, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(centroids, data):\n",
    "    distance_instance_to_clusters = np.zeros((len(data), k))\n",
    "    for instance in range(len(data)):\n",
    "        for cluster in range(k):\n",
    "            distance_instance_to_clusters[instance, cluster] = euclidean_distance(data[instance, :-2], centroids[cluster])\n",
    "        labels[instance] = np.argmin(distance_instance_to_clusters[instance])\n",
    "    return labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress(data, labels, title, centroids):\n",
    "    figure, axs = plt.subplots(nrows=1, ncols=2,figsize=(14,4))\n",
    "                               \n",
    "    figure.suptitle(f'data {title}/10', fontsize= 16)\n",
    "    \n",
    "    axs[0].scatter(data[:,5], data[:,4], c=labels, cmap='rainbow', alpha=0.7)\n",
    "    axs[0].set_ylabel('Number of cars')\n",
    "    axs[0].set_xlabel('Time')\n",
    "    if title > 7:\n",
    "        axs[0].axvline(x=143, color='g')\n",
    "\n",
    "    axs[1].scatter(data[:,1], data[:,3], c=labels, cmap='rainbow', alpha=0.7)\n",
    "    axs[1].set_ylabel('3rd Quartile')\n",
    "    axs[1].set_xlabel('1st Quartlie')\n",
    "    for i in range(len(centroids)):\n",
    "        axs[1].scatter(centroids[i,1], centroids[i, 3], c='black', marker='x')\n",
    "                               \n",
    "    figure.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    plt.show(figure)\n",
    "    plt.close(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sil_score(data, labels):\n",
    "    return metrics.silhouette_score(data, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cal_score(data, labels):\n",
    "    return metrics.calinski_harabasz_score(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "def get_davies_score(data, labels):\n",
    "    return davies_bouldin_score(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start with classic K-Means algorithm to initialize the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_size = len(k_np[0]) - 2\n",
    "number_of_samples = len(k_np)\n",
    "\n",
    "centroids_old = np.zeros((k, feat_size))\n",
    "centroids = np.zeros((k, feat_size))  # means of all the clusters\n",
    "counts = np.zeros(k) # number of points for each of the cluster\n",
    "\n",
    "labels_new = np.zeros(number_of_samples)\n",
    "\n",
    "random_centroids = np.random.choice(number_of_samples, k, replace = False)\n",
    "\n",
    "# initialize the clusters here\n",
    "for index in range(k):\n",
    "    centroids[index] = k_np[random_centroids[index], :-2]\n",
    "\n",
    "# for loop for max number of iterations:\n",
    "for iteration in range(100):\n",
    "# make clusters    \n",
    "    centroids_old = copy.deepcopy(centroids)\n",
    "    \n",
    "    #distances of each of the samples to each cluster\n",
    "    distance_instance_to_clusters = np.zeros((number_of_samples, k))\n",
    "    for instance in range(number_of_samples):\n",
    "        for cluster in range(k):\n",
    "            distance_instance_to_clusters[instance, cluster] = euclidean_distance(k_np[instance, :-2],centroids[cluster])\n",
    "        # choose closets cluster for that instance\n",
    "        labels_new[instance] = np.argmin(distance_instance_to_clusters[instance])\n",
    "        \n",
    "# update centroids\n",
    "    for i in range(k):\n",
    "        clusters = k_np[labels_new==i, :-2]\n",
    "        centroids[i] = np.mean(clusters, axis=0)\n",
    "\n",
    "# plot each iteration for debugging\n",
    "    plot_iteration(k_np, labels_new, centroids, iteration)\n",
    "    \n",
    "# check if converged\n",
    "    centroid_distances = [euclidean_distance(centroids_old[i], centroids[i]) for i in range(k)]\n",
    "    if sum(centroid_distances) == 0:\n",
    "        print(f'Converged somehow (?) at loop {iteration+1}')\n",
    "        break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = copy.deepcopy(labels_new)\n",
    "old_data = copy.deepcopy(k_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "labels_dict[f'fit_1'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_nmpys_for_graphs = []\n",
    "list_of_nmpys_for_graphs.append(old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_dfs_rest[0])\n",
    "\n",
    "labels_for_plotting = np.zeros(26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 2\n",
    "s = get_sil_score(old_data[:, :-2], labels_dict[f'fit_1'])\n",
    "c = get_cal_score(old_data[:, :-2], labels_dict[f'fit_1'])\n",
    "d = get_davies_score(old_data[:, :-2], labels_dict[f'fit_1'])\n",
    "print(s)\n",
    "for set_df in list_of_dfs_rest:\n",
    "    new_data = set_df\n",
    "    for index in range(len(new_data)):\n",
    "        label, centroids, counts = add_new_instance(centroids, counts, k, new_data[index, :-2])\n",
    "        labels = np.append(labels, label)\n",
    "        old_data = np.append(old_data, new_data[index].reshape(1,-1), axis=0)\n",
    "    \n",
    "    labels_dict[f'fit_{counter}'] = predict(centroids,old_data)\n",
    "    list_of_nmpys_for_graphs.append(old_data)\n",
    "#     plot_progress(old_data, labels_dict[f'fit_{counter}'], counter, centroids)\n",
    "    s = get_sil_score(old_data[:, :-2], labels_dict[f'fit_{counter}'])\n",
    "    c = get_cal_score(old_data[:, :-2], labels_dict[f'fit_{counter}'])\n",
    "    d = get_davies_score(old_data[:, :-2], labels_dict[f'fit_{counter}'])\n",
    "    print(s)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_sil_score(list_of_nmpys_for_graphs[-1], labels_dict[f'fit_{counter-1}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(list_of_nmpys_for_graphs[-1][:, 5], list_of_nmpys_for_graphs[-1][:, 4], c =labels_dict[f'fit_{counter-1}'], cmap='rainbow', alpha=0.7 )\n",
    "# plt.ylabel('Car Number')\n",
    "# plt.xlabel('Time')\n",
    "# plt.title('k = 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_counter = 0\n",
    "row_counter = 0\n",
    "\n",
    "fit_number = 1\n",
    "\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "\n",
    "figure, axs = plt.subplots(nrows=nrows, ncols=ncols,figsize=(14,9))\n",
    "\n",
    "for i in list_of_nmpys_for_graphs:\n",
    "    \n",
    "#     numpy_array = i.to_numpy()\n",
    "    \n",
    "    figure.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    axs[row_counter,col_counter].scatter(i[:, 5], i[:, 4], c =labels_dict[f'fit_{fit_number}'], cmap='rainbow', alpha=0.7 )\n",
    "    axs[row_counter,col_counter].set_xlabel('Time of the day')\n",
    "    axs[row_counter,col_counter].set_ylim(0, 750)\n",
    "    axs[row_counter,col_counter].set_ylabel('Car number')\n",
    "    axs[row_counter,col_counter].set_title(f'Fit {fit_number}')\n",
    "    \n",
    "#     if fit_number >= 9:\n",
    "#         axs[row_counter,col_counter].axvline(x=143, color='g')\n",
    "    if col_counter == (ncols-1):\n",
    "        col_counter = 0\n",
    "        row_counter += 1\n",
    "    else:\n",
    "        col_counter += 1\n",
    "    \n",
    "    fit_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs_rest_2 = data_split_modified_z_12[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for set_df in list_of_dfs_rest_2:\n",
    "    new_data = set_df\n",
    "    for index in range(len(new_data)):\n",
    "        label, centroids, counts = add_new_instance(centroids, counts, k, new_data[index, :-2])\n",
    "        labels = np.append(labels, label)\n",
    "        old_data = np.append(old_data, new_data[index].reshape(1,-1), axis=0)\n",
    "    \n",
    "    labels_dict[f'fit_{counter}'] = predict(centroids,old_data)\n",
    "    list_of_nmpys_for_graphs.append(old_data)\n",
    "#     plot_progress(old_data, labels_dict[f'fit_{counter}'], counter, centroids)\n",
    "    s = get_sil_score(old_data[:, :-2], labels_dict[f'fit_{counter}'])\n",
    "    c = get_cal_score(old_data[:, :-2], labels_dict[f'fit_{counter}'])\n",
    "    d = get_davies_score(old_data[:, :-2], labels_dict[f'fit_{counter}'])\n",
    "    print(s)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_counter = 0\n",
    "row_counter = 0\n",
    "\n",
    "fit_number = 1\n",
    "\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "figure, axs = plt.subplots(nrows=nrows, ncols=ncols,figsize=(20,15))\n",
    "\n",
    "for i in list_of_nmpys_for_graphs:\n",
    "    \n",
    "#     numpy_array = i.to_numpy()\n",
    "    \n",
    "    figure.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    axs[row_counter,col_counter].scatter(i[:, 5], i[:, 4], c =labels_dict[f'fit_{fit_number}'], cmap='rainbow', alpha=0.7 )\n",
    "    axs[row_counter,col_counter].set_xlabel('Time of the day')\n",
    "    axs[row_counter,col_counter].set_ylim(0, 750)\n",
    "    axs[row_counter,col_counter].set_ylabel('Car number')\n",
    "    axs[row_counter,col_counter].set_title(f'Fit {fit_number}')\n",
    "    \n",
    "    if fit_number >= 9:\n",
    "        axs[row_counter,col_counter].axvline(x=143, color='g')\n",
    "    if col_counter == (ncols-1):\n",
    "        col_counter = 0\n",
    "        row_counter += 1\n",
    "    else:\n",
    "        col_counter += 1\n",
    "    \n",
    "    fit_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sil_score(old_data[:, :-2], labels_dict[f'fit_{counter-1}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list_of_nmpys_for_graphs[-1][:, 5], list_of_nmpys_for_graphs[-1][:, 4], c =labels_dict[f'fit_{counter-1}'], cmap='rainbow', alpha=0.7 )\n",
    "plt.ylabel('Car Number')\n",
    "plt.xlabel('Time')\n",
    "plt.axvline(x=143, color='g')\n",
    "plt.title('k = 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
